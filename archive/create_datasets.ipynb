{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/james/CodingProjects/TextNTabularExplanations/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "from datasets import Dataset, DatasetDict, load_dataset\n",
                "from auto_mm_bench.datasets import dataset_registry\n",
                "from sklearn.preprocessing import OrdinalEncoder\n",
                "from src.utils import legacy_get_dataset_info\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset creation here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                       \r"
                    ]
                }
            ],
            "source": [
                "for dataset_name in [\n",
                "    \"wine_reviews\",\n",
                "    \"fake_job_postings2\",\n",
                "    \"product_sentiment_machine_hack\",\n",
                "    \"kick_starter_funding\",\n",
                "    \"jigsaw_unintended_bias100K\",\n",
                "    \"imdb_genre_prediction\",\n",
                "]:\n",
                "    di = get_dataset_info(dataset_name)\n",
                "    train_dataset = dataset_registry.create(dataset_name, \"train\")\n",
                "    test_dataset = dataset_registry.create(dataset_name, \"test\")\n",
                "    cols = train_dataset.feature_columns + train_dataset.label_columns\n",
                "\n",
                "    train_txt = train_dataset.data[cols]\n",
                "    test_txt = test_dataset.data[cols]\n",
                "\n",
                "    # load dataset from dataframe\n",
                "    train_ds = Dataset.from_pandas(train_txt)\n",
                "    train_ds = train_ds.class_encode_column(train_dataset.label_columns[0])\n",
                "    test_ds = Dataset.from_pandas(test_txt)\n",
                "    test_ds = test_ds.class_encode_column(train_dataset.label_columns[0])\n",
                "\n",
                "    train_ds = train_ds.train_test_split(\n",
                "        test_size=0.15, seed=42, stratify_by_column=train_dataset.label_columns[0]\n",
                "    )\n",
                "\n",
                "    ds = DatasetDict(\n",
                "        {\"train\": train_ds[\"train\"],\n",
                "            \"validation\": train_ds[\"test\"], \"test\": test_ds}\n",
                "    )\n",
                "\n",
                "    # Now we have made the split but still need to deal with missing values, and that depends on the column type\n",
                "\n",
                "    # All as text\n",
                "    train_all_text = ds[\"train\"].to_pandas()\n",
                "    val_all_text = ds[\"validation\"].to_pandas()\n",
                "    test_all_text = ds[\"test\"].to_pandas()\n",
                "\n",
                "    train_all_text[train_dataset.feature_columns] = train_all_text[\n",
                "        train_dataset.feature_columns\n",
                "    ].astype(\"str\")\n",
                "    val_all_text[train_dataset.feature_columns] = val_all_text[\n",
                "        train_dataset.feature_columns\n",
                "    ].astype(\"str\")\n",
                "    test_all_text[train_dataset.feature_columns] = test_all_text[\n",
                "        train_dataset.feature_columns\n",
                "    ].astype(\"str\")\n",
                "\n",
                "    ds_all_text = DatasetDict(\n",
                "        {\n",
                "            \"train\": Dataset.from_pandas(train_all_text),\n",
                "            \"validation\": Dataset.from_pandas(val_all_text),\n",
                "            \"test\": Dataset.from_pandas(test_all_text),\n",
                "        }\n",
                "    )\n",
                "\n",
                "    ds_all_text.push_to_hub(dataset_name + \"_all_text\")\n",
                "\n",
                "    # Not all as text\n",
                "    train = ds[\"train\"].to_pandas()\n",
                "    val = ds[\"validation\"].to_pandas()\n",
                "    test = ds[\"test\"].to_pandas()\n",
                "\n",
                "    train[di.text_cols] = train[di.text_cols].astype(\"str\")\n",
                "    val[di.text_cols] = val[di.text_cols].astype(\"str\")\n",
                "    test[di.text_cols] = test[di.text_cols].astype(\"str\")\n",
                "\n",
                "    # ds.push_to_hub(dataset_name)\n",
                "    if len(di.categorical_cols) > 0:\n",
                "        train[di.categorical_cols] = train[di.categorical_cols].astype(\n",
                "            \"category\")\n",
                "\n",
                "        enc = OrdinalEncoder(encoded_missing_value=-1)\n",
                "        train[di.categorical_cols] = enc.fit_transform(\n",
                "            train[di.categorical_cols])\n",
                "\n",
                "        val[di.categorical_cols] = val[di.categorical_cols].astype(\"category\")\n",
                "        val[di.categorical_cols] = enc.transform(val[di.categorical_cols])\n",
                "\n",
                "        test[di.categorical_cols] = test[di.categorical_cols].astype(\n",
                "            \"category\")\n",
                "        test[di.categorical_cols] = enc.transform(test[di.categorical_cols])\n",
                "\n",
                "    ds2 = DatasetDict(\n",
                "        {\n",
                "            \"train\": Dataset.from_pandas(train),\n",
                "            \"validation\": Dataset.from_pandas(val),\n",
                "            \"test\": Dataset.from_pandas(test),\n",
                "        }\n",
                "    )\n",
                "\n",
                "    ds2.push_to_hub(dataset_name + \"_ordinal\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "di = get_dataset_info(dataset_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetInfo(ds_name=None, tab_cols=['Year', 'Runtime (Minutes)', 'Rating', 'Votes', 'Revenue (Millions)', 'Metascore', 'Rank'], categorical_cols=[], text_cols=['Description'], label_col='Genre_is_Drama', num_labels=2, prob_type='single_label_classification', wandb_proj_name='IMDB Genre', text_model_name=None)"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "di"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}